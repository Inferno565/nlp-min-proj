# Legal Text Classification using Natural Language Processing  

## Project Overview  
This project is part of the **Natural Language Processing (NLP) course** for **Semester 6** students at **Pillai College of Engineering**. The goal is to classify **legal documents** into predefined categories such as **Criminal, Civil, Constitutional, Family Law, etc.** using **Machine Learning (ML), Deep Learning (DL), and Language Models**.  

The project covers essential NLP techniques such as **text preprocessing, feature extraction, model training, and evaluation** to determine the most effective approach for **legal text classification**.  

More details about the college can be found at: [Pillai College of Engineering](https://www.pce.ac.in/)  

---

## Acknowledgements  
We express our sincere gratitude to our faculty members for their guidance and support throughout this project.  

**Theory Faculty:**  
- Dhiraj Amin  
- Sharvari Govilkar  

**Lab Faculty:**  
- Dhiraj Amin  
- Neha Ashok  
- Shubhangi Chavan  

---
## Project Title  
**Legal Text Classification Using Natural Language Processing** 

## Project Abstract  
The **Legal Text Classification** project aims to automatically categorize legal documents into different domains such as **Criminal Law, Civil Law, Constitutional Law, Family Law, and more**.  

Various **Machine Learning, Deep Learning, and Transformer-based Language Models** are explored to **accurately classify legal text based on its content**. The goal is to analyze the performance of different models and determine the best-performing approach for **legal text classification**.  

---

## Algorithms Used  

### Machine Learning Algorithms  
- Logistic Regression  
- Support Vector Machine (SVM)  
- Random Forest Classifier  

### Deep Learning Algorithms  
- Convolutional Neural Networks (CNN)  
- Recurrent Neural Networks (RNN)  
- Long Short-Term Memory (LSTM)  

### Language Models  
- GPT  
- BERT (Bidirectional Encoder Representations from Transformers)  

---

## Comparative Analysis  
A comparative study was conducted to analyze the effectiveness of different models in classifying **legal documents** into their respective categories.  

| Model Type  | Accuracy (%) | Precision (%) | Recall (%) | F1-Score (%) |
|------------|-------------|--------------|------------|--------------|
| Logistic Regression | 50.2 | 55.9 | 55 | 48 |
| SVM (Support Vector Machine) | 49 | 45 | 49 | 38.45 |
| Random Forest | 55.5 | 57.3 | 55.5 | 47.02 |
| CNN (Convolutional Neural Networks) | 99.9 | 99.9 | 99.9 | 99.9 |
| LSTM (Long Short-Term Memory) | 57.0 | 54.0 | 57.0 | 58.0 |
| BERT (Bidirectional Encoder Representations from Transformers) | 99.9 | 99.9 | 99.9 | 99.9 |
| RoBERTa (Robustly Optimized BERT Approach) | 99.9 | 99.9 | 99.9 | 99.9 |

---

## Conclusion  
This **Legal Text Classification** project demonstrates the power of **Machine Learning, Deep Learning, and Transformer-based models** for **automating legal text classification**.  

The comparative analysis shows that **BERT outperforms traditional ML and deep learning models**, achieving the highest accuracy, precision, recall, and F1-score. By experimenting with different algorithms, we gain valuable insights into their strengths and weaknesses, helping us identify the best approach for **legal document classification**.  
